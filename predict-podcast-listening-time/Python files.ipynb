{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"D:/Predict Podcast Listening Time ML/\"\n",
    "train= pd.read_csv(path + \"train.csv\")\n",
    "test=pd.read_csv(path + \"test.csv\")\n",
    "sample_submission=pd.read_csv(path + \"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Data:\n",
      "   id     Podcast_Name Episode_Title  Episode_Length_minutes       Genre  \\\n",
      "0   0  Mystery Matters    Episode 98                     NaN  True Crime   \n",
      "1   1    Joke Junction    Episode 26                  119.80      Comedy   \n",
      "2   2   Study Sessions    Episode 16                   73.90   Education   \n",
      "3   3   Digital Digest    Episode 45                   67.17  Technology   \n",
      "4   4      Mind & Body    Episode 86                  110.51      Health   \n",
      "\n",
      "   Host_Popularity_percentage Publication_Day Publication_Time  \\\n",
      "0                       74.81        Thursday            Night   \n",
      "1                       66.95        Saturday        Afternoon   \n",
      "2                       69.97         Tuesday          Evening   \n",
      "3                       57.22          Monday          Morning   \n",
      "4                       80.07          Monday        Afternoon   \n",
      "\n",
      "   Guest_Popularity_percentage  Number_of_Ads Episode_Sentiment  \\\n",
      "0                          NaN            0.0          Positive   \n",
      "1                        75.95            2.0          Negative   \n",
      "2                         8.97            0.0          Negative   \n",
      "3                        78.70            2.0          Positive   \n",
      "4                        58.68            3.0           Neutral   \n",
      "\n",
      "   Listening_Time_minutes  \n",
      "0                31.41998  \n",
      "1                88.01241  \n",
      "2                44.92531  \n",
      "3                46.27824  \n",
      "4                75.61031  \n",
      "\n",
      "Test Data:\n",
      "       id         Podcast_Name Episode_Title  Episode_Length_minutes  \\\n",
      "0  750000  Educational Nuggets    Episode 73                   78.96   \n",
      "1  750001          Sound Waves    Episode 23                   27.87   \n",
      "2  750002        Joke Junction    Episode 11                   69.10   \n",
      "3  750003        Comedy Corner    Episode 73                  115.39   \n",
      "4  750004         Life Lessons    Episode 50                   72.32   \n",
      "\n",
      "       Genre  Host_Popularity_percentage Publication_Day Publication_Time  \\\n",
      "0  Education                       38.11        Saturday          Evening   \n",
      "1      Music                       71.29          Sunday          Morning   \n",
      "2     Comedy                       67.89          Friday          Evening   \n",
      "3     Comedy                       23.40          Sunday          Morning   \n",
      "4  Lifestyle                       58.10       Wednesday          Morning   \n",
      "\n",
      "   Guest_Popularity_percentage  Number_of_Ads Episode_Sentiment  \n",
      "0                        53.33            1.0           Neutral  \n",
      "1                          NaN            0.0           Neutral  \n",
      "2                        97.51            0.0          Positive  \n",
      "3                        51.75            2.0          Positive  \n",
      "4                        11.30            2.0           Neutral  \n",
      "\n",
      "Train info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 750000 entries, 0 to 749999\n",
      "Data columns (total 12 columns):\n",
      " #   Column                       Non-Null Count   Dtype  \n",
      "---  ------                       --------------   -----  \n",
      " 0   id                           750000 non-null  int64  \n",
      " 1   Podcast_Name                 750000 non-null  object \n",
      " 2   Episode_Title                750000 non-null  object \n",
      " 3   Episode_Length_minutes       662907 non-null  float64\n",
      " 4   Genre                        750000 non-null  object \n",
      " 5   Host_Popularity_percentage   750000 non-null  float64\n",
      " 6   Publication_Day              750000 non-null  object \n",
      " 7   Publication_Time             750000 non-null  object \n",
      " 8   Guest_Popularity_percentage  603970 non-null  float64\n",
      " 9   Number_of_Ads                749999 non-null  float64\n",
      " 10  Episode_Sentiment            750000 non-null  object \n",
      " 11  Listening_Time_minutes       750000 non-null  float64\n",
      "dtypes: float64(5), int64(1), object(6)\n",
      "memory usage: 68.7+ MB\n",
      "\n",
      "Test info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 250000 entries, 0 to 249999\n",
      "Data columns (total 11 columns):\n",
      " #   Column                       Non-Null Count   Dtype  \n",
      "---  ------                       --------------   -----  \n",
      " 0   id                           250000 non-null  int64  \n",
      " 1   Podcast_Name                 250000 non-null  object \n",
      " 2   Episode_Title                250000 non-null  object \n",
      " 3   Episode_Length_minutes       221264 non-null  float64\n",
      " 4   Genre                        250000 non-null  object \n",
      " 5   Host_Popularity_percentage   250000 non-null  float64\n",
      " 6   Publication_Day              250000 non-null  object \n",
      " 7   Publication_Time             250000 non-null  object \n",
      " 8   Guest_Popularity_percentage  201168 non-null  float64\n",
      " 9   Number_of_Ads                250000 non-null  float64\n",
      " 10  Episode_Sentiment            250000 non-null  object \n",
      "dtypes: float64(4), int64(1), object(6)\n",
      "memory usage: 21.0+ MB\n",
      "\n",
      "Train Description:\n",
      "                  id  Episode_Length_minutes  Host_Popularity_percentage  \\\n",
      "count  750000.000000           662907.000000               750000.000000   \n",
      "mean   374999.500000               64.504738                   59.859901   \n",
      "std    216506.495284               32.969603                   22.873098   \n",
      "min         0.000000                0.000000                    1.300000   \n",
      "25%    187499.750000               35.730000                   39.410000   \n",
      "50%    374999.500000               63.840000                   60.050000   \n",
      "75%    562499.250000               94.070000                   79.530000   \n",
      "max    749999.000000              325.240000                  119.460000   \n",
      "\n",
      "       Guest_Popularity_percentage  Number_of_Ads  Listening_Time_minutes  \n",
      "count                603970.000000  749999.000000           750000.000000  \n",
      "mean                     52.236449       1.348855               45.437406  \n",
      "std                      28.451241       1.151130               27.138306  \n",
      "min                       0.000000       0.000000                0.000000  \n",
      "25%                      28.380000       0.000000               23.178350  \n",
      "50%                      53.580000       1.000000               43.379460  \n",
      "75%                      76.600000       2.000000               64.811580  \n",
      "max                     119.910000     103.910000              119.970000  \n",
      "\n",
      "Test Description:\n",
      "                  id  Episode_Length_minutes  Host_Popularity_percentage  \\\n",
      "count  250000.000000            2.212640e+05               250000.000000   \n",
      "mean   874999.500000            4.192987e+02                   59.716491   \n",
      "std     72168.927986            1.668545e+05                   22.880028   \n",
      "min    750000.000000            2.470000e+00                    2.490000   \n",
      "25%    812499.750000            3.578000e+01                   39.250000   \n",
      "50%    874999.500000            6.397000e+01                   59.900000   \n",
      "75%    937499.250000            9.415000e+01                   79.390000   \n",
      "max    999999.000000            7.848626e+07                  117.760000   \n",
      "\n",
      "       Guest_Popularity_percentage  Number_of_Ads  \n",
      "count                201168.000000  250000.000000  \n",
      "mean                     52.192796       1.355852  \n",
      "std                      28.445034       4.274399  \n",
      "min                       0.000000       0.000000  \n",
      "25%                      28.320000       0.000000  \n",
      "50%                      53.360000       1.000000  \n",
      "75%                      76.560000       2.000000  \n",
      "max                     116.820000    2063.000000  \n"
     ]
    }
   ],
   "source": [
    "#Preview the train file\n",
    "print(\"\\nTrain Data:\")\n",
    "print(train.head())\n",
    "print(\"\\nTest Data:\")\n",
    "print(test.head())\n",
    "print(\"\\nTrain info:\")\n",
    "train.info()\n",
    "print(\"\\nTest info:\")\n",
    "test.info() \n",
    "print(\"\\nTrain Description:\")\n",
    "print(train.describe())\n",
    "print(\"\\nTest Description:\")\n",
    "print(test.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medians for replacing missing values ➜ Episode length: 63.84, Guest popularity: 53.58, Ads: 1.00\n",
      "\n",
      "Missing values in the training dataset:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARAH W\\AppData\\Local\\Temp\\ipykernel_756\\2442121733.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train['Episode_Length_minutes'].fillna(len_median, inplace=True)\n",
      "C:\\Users\\SARAH W\\AppData\\Local\\Temp\\ipykernel_756\\2442121733.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train['Guest_Popularity_percentage'].fillna(guest_median, inplace=True)\n",
      "C:\\Users\\SARAH W\\AppData\\Local\\Temp\\ipykernel_756\\2442121733.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train['Number_of_Ads'].fillna(ads_median, inplace=True)\n",
      "C:\\Users\\SARAH W\\AppData\\Local\\Temp\\ipykernel_756\\2442121733.py:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test['Episode_Length_minutes'].fillna(len_median, inplace=True)\n",
      "C:\\Users\\SARAH W\\AppData\\Local\\Temp\\ipykernel_756\\2442121733.py:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test['Guest_Popularity_percentage'].fillna(guest_median, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                             0\n",
      "Podcast_Name                   0\n",
      "Episode_Title                  0\n",
      "Episode_Length_minutes         0\n",
      "Genre                          0\n",
      "Host_Popularity_percentage     0\n",
      "Publication_Day                0\n",
      "Publication_Time               0\n",
      "Guest_Popularity_percentage    0\n",
      "Number_of_Ads                  0\n",
      "Episode_Sentiment              0\n",
      "Listening_Time_minutes         0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in the test dataset:\n",
      "id                             0\n",
      "Podcast_Name                   0\n",
      "Episode_Title                  0\n",
      "Episode_Length_minutes         0\n",
      "Genre                          0\n",
      "Host_Popularity_percentage     0\n",
      "Publication_Day                0\n",
      "Publication_Time               0\n",
      "Guest_Popularity_percentage    0\n",
      "Number_of_Ads                  0\n",
      "Episode_Sentiment              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Calculate the median of the column that have missing values in the training dataset \n",
    "len_median=train['Episode_Length_minutes'].median()\n",
    "guest_median=train['Guest_Popularity_percentage'].median()\n",
    "ads_median=train['Number_of_Ads'].median()\n",
    "\n",
    "print(f\"Medians for replacing missing values ➜ Episode length: {len_median:.2f}, Guest popularity: {guest_median:.2f}, Ads: {ads_median:.2f}\")\n",
    "\n",
    "#Filling the missing values in the training dataset\n",
    "train['Episode_Length_minutes'].fillna(len_median, inplace=True)\n",
    "train['Guest_Popularity_percentage'].fillna(guest_median, inplace=True)\n",
    "train['Number_of_Ads'].fillna(ads_median, inplace=True)\n",
    "\n",
    "#Filling the missing values in the test dataset using the medians from the training dataset\n",
    "#Because train datset is used to train the model \n",
    "test['Episode_Length_minutes'].fillna(len_median, inplace=True)\n",
    "test['Guest_Popularity_percentage'].fillna(guest_median, inplace=True)\n",
    "\n",
    "#Check for the missing values in the training dataset and the test dataset\n",
    "print(\"\\nMissing values in the training dataset:\")\n",
    "print(train.isnull().sum())\n",
    "print(\"\\nMissing values in the test dataset:\")\n",
    "print(test.isnull().sum())  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the categorical variables to numerical variables\n",
    "#Map Prediction_Time to numerical values\n",
    "time_map={\n",
    "    'Morning': 9,\n",
    "    'Afternoon': 15, \n",
    "    'Evening': 19,\n",
    "    'Night': 22\n",
    "}\n",
    "\n",
    "train['Publication_Hour'] = train['Publication_Time'].map(time_map)\n",
    "test['Publication_Hour'] = test['Publication_Time'].map(time_map)\n",
    "#Map publication day to numerical values\n",
    "day_map={\n",
    "    'Monday': 1,\n",
    "    'Tuesday': 2,\n",
    "    'Wednesday': 3,\n",
    "    'Thursday': 4,\n",
    "    'Friday': 5,\n",
    "    'Saturday': 6,\n",
    "    'Sunday': 7\n",
    "}\n",
    "train['Publication_Day_Num'] =train['Publication_Day'].map(day_map)\n",
    "test['Publication_Day_Num'] =test['Publication_Day'].map(day_map)\n",
    "\n",
    "#Drop unnecessary columns(Publication_Time, Publication_Day)\n",
    "train.drop(['Publication_Time', 'Publication_Day'], axis=1, inplace=True)\n",
    "test.drop(['Publication_Time', 'Publication_Day'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 750000 entries, 0 to 749999\n",
      "Data columns (total 12 columns):\n",
      " #   Column                       Non-Null Count   Dtype  \n",
      "---  ------                       --------------   -----  \n",
      " 0   id                           750000 non-null  int64  \n",
      " 1   Podcast_Name                 750000 non-null  object \n",
      " 2   Episode_Title                750000 non-null  object \n",
      " 3   Episode_Length_minutes       750000 non-null  float64\n",
      " 4   Genre                        750000 non-null  object \n",
      " 5   Host_Popularity_percentage   750000 non-null  float64\n",
      " 6   Guest_Popularity_percentage  750000 non-null  float64\n",
      " 7   Number_of_Ads                750000 non-null  float64\n",
      " 8   Episode_Sentiment            750000 non-null  object \n",
      " 9   Listening_Time_minutes       750000 non-null  float64\n",
      " 10  Publication_Hour             750000 non-null  int64  \n",
      " 11  Publication_Day_Num          750000 non-null  int64  \n",
      "dtypes: float64(5), int64(3), object(4)\n",
      "memory usage: 68.7+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 250000 entries, 0 to 249999\n",
      "Data columns (total 11 columns):\n",
      " #   Column                       Non-Null Count   Dtype  \n",
      "---  ------                       --------------   -----  \n",
      " 0   id                           250000 non-null  int64  \n",
      " 1   Podcast_Name                 250000 non-null  object \n",
      " 2   Episode_Title                250000 non-null  object \n",
      " 3   Episode_Length_minutes       250000 non-null  float64\n",
      " 4   Genre                        250000 non-null  object \n",
      " 5   Host_Popularity_percentage   250000 non-null  float64\n",
      " 6   Guest_Popularity_percentage  250000 non-null  float64\n",
      " 7   Number_of_Ads                250000 non-null  float64\n",
      " 8   Episode_Sentiment            250000 non-null  object \n",
      " 9   Publication_Hour             250000 non-null  int64  \n",
      " 10  Publication_Day_Num          250000 non-null  int64  \n",
      "dtypes: float64(4), int64(3), object(4)\n",
      "memory usage: 21.0+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()\n",
    "test.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create label encoders\n",
    "genre_encoder = LabelEncoder()\n",
    "sentiment_encoder = LabelEncoder()\n",
    "\n",
    "# Fit on training and apply to both train and test\n",
    "train['Genre'] = genre_encoder.fit_transform(train['Genre'])\n",
    "test['Genre'] = genre_encoder.transform(test['Genre'])\n",
    "\n",
    "train['Episode_Sentiment'] = sentiment_encoder.fit_transform(train['Episode_Sentiment'])\n",
    "test['Episode_Sentiment'] = sentiment_encoder.transform(test['Episode_Sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['id', 'Podcast_Name', 'Episode_Title']\n",
    "\n",
    "train.drop(columns=columns_to_drop, axis=1, inplace=True)\n",
    "test.drop(columns=columns_to_drop, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 750000 entries, 0 to 749999\n",
      "Data columns (total 9 columns):\n",
      " #   Column                       Non-Null Count   Dtype  \n",
      "---  ------                       --------------   -----  \n",
      " 0   Episode_Length_minutes       750000 non-null  float64\n",
      " 1   Genre                        750000 non-null  int64  \n",
      " 2   Host_Popularity_percentage   750000 non-null  float64\n",
      " 3   Guest_Popularity_percentage  750000 non-null  float64\n",
      " 4   Number_of_Ads                750000 non-null  float64\n",
      " 5   Episode_Sentiment            750000 non-null  int64  \n",
      " 6   Listening_Time_minutes       750000 non-null  float64\n",
      " 7   Publication_Hour             750000 non-null  int64  \n",
      " 8   Publication_Day_Num          750000 non-null  int64  \n",
      "dtypes: float64(5), int64(4)\n",
      "memory usage: 51.5 MB\n",
      "None\n",
      "   Episode_Length_minutes  Genre  Host_Popularity_percentage  \\\n",
      "0                   78.96      2                       38.11   \n",
      "1                   27.87      5                       71.29   \n",
      "2                   69.10      1                       67.89   \n",
      "3                  115.39      1                       23.40   \n",
      "4                   72.32      4                       58.10   \n",
      "\n",
      "   Guest_Popularity_percentage  Number_of_Ads  Episode_Sentiment  \\\n",
      "0                        53.33            1.0                  1   \n",
      "1                        53.58            0.0                  1   \n",
      "2                        97.51            0.0                  2   \n",
      "3                        51.75            2.0                  2   \n",
      "4                        11.30            2.0                  1   \n",
      "\n",
      "   Publication_Hour  Publication_Day_Num  \n",
      "0                19                    6  \n",
      "1                 9                    7  \n",
      "2                19                    5  \n",
      "3                 9                    7  \n",
      "4                 9                    3  \n"
     ]
    }
   ],
   "source": [
    "print(train.info())\n",
    "print(test.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List columns to scale\n",
    "columns_to_scale = [\n",
    "    'Episode_Length_minutes',\n",
    "    'Host_Popularity_percentage',\n",
    "    'Guest_Popularity_percentage',\n",
    "    'Number_of_Ads',\n",
    "    'Publication_Hour',\n",
    "    'Publication_Day_Num'\n",
    "]\n",
    "\n",
    "# Initialize scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit scaler on training data and transform\n",
    "train[columns_to_scale] = scaler.fit_transform(train[columns_to_scale])\n",
    "\n",
    "# Transform test data with the same scaler\n",
    "test[columns_to_scale] = scaler.transform(test[columns_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode_Length_minutes         4.634918e-16\n",
      "Host_Popularity_percentage    -6.141552e-16\n",
      "Guest_Popularity_percentage   -9.439797e-17\n",
      "Number_of_Ads                 -1.552110e-16\n",
      "Publication_Hour               3.294266e-16\n",
      "Publication_Day_Num           -3.172810e-17\n",
      "dtype: float64\n",
      "Episode_Length_minutes         1.000001\n",
      "Host_Popularity_percentage     1.000001\n",
      "Guest_Popularity_percentage    1.000001\n",
      "Number_of_Ads                  1.000001\n",
      "Publication_Hour               1.000001\n",
      "Publication_Day_Num            1.000001\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(train[columns_to_scale].mean())\n",
    "print(train[columns_to_scale].std())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop('Listening_Time_minutes', axis=1)\n",
    "y_train = train['Listening_Time_minutes']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = lgb.Dataset(X_train, label=y_train)  # Training part\n",
    "val_data = lgb.Dataset(X_val, label=y_val)        # Validation part\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'regression',        # We're predicting a number (Listening time)\n",
    "    'metric': 'rmse',                 # We'll measure error using RMSE\n",
    "    'boosting_type': 'gbdt',          # Gradient Boosted Trees (default method)\n",
    "    'learning_rate': 0.1,             # How fast it learns (smaller = slower but better)\n",
    "    'num_leaves': 31,                 # Complexity of the trees (start simple)\n",
    "    'verbose': -1,                    # Don't print too much stuff\n",
    "    'random_state': 42                # For consistent results\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttrain's rmse: 13.0536\tvalid's rmse: 13.0729\n",
      "[200]\ttrain's rmse: 12.9628\tvalid's rmse: 13.0495\n",
      "[300]\ttrain's rmse: 12.8904\tvalid's rmse: 13.0328\n",
      "[400]\ttrain's rmse: 12.8276\tvalid's rmse: 13.0228\n",
      "[500]\ttrain's rmse: 12.7691\tvalid's rmse: 13.0122\n",
      "[600]\ttrain's rmse: 12.7139\tvalid's rmse: 13.0033\n",
      "[700]\ttrain's rmse: 12.6645\tvalid's rmse: 12.9971\n",
      "[800]\ttrain's rmse: 12.6168\tvalid's rmse: 12.991\n",
      "[900]\ttrain's rmse: 12.5733\tvalid's rmse: 12.9854\n",
      "[1000]\ttrain's rmse: 12.5316\tvalid's rmse: 12.9816\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[996]\ttrain's rmse: 12.5339\tvalid's rmse: 12.9813\n"
     ]
    }
   ],
   "source": [
    "model = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    valid_sets=[train_data, val_data],\n",
    "    valid_names=['train', 'valid'],\n",
    "    num_boost_round=1000,\n",
    "    callbacks=[early_stopping(50), log_evaluation(100)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This assumes your test set is already preprocessed and scaled just like train\n",
    "X_test = test.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Predict on test set using the trained model\n",
    "y_test_pred = model.predict(X_test, num_iteration=model.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load the sample submission file\n",
    "submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load the sample submission file\n",
    "submission = pd.read_csv('sample_submission.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Insert your predictions into the correct column\n",
    "submission['Listening_Time_minutes'] = y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Save your submission file (name it meaningfully)\n",
    "submission.to_csv('submission_lgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
